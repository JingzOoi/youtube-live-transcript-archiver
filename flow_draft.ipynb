{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Stream Analysis Flow (Professional V2)\n",
    "This notebook processes YouTube transcripts and live chat logs to analyze engagement, spikes, and keywords.\n",
    "\n",
    "**Refactored for:** Robust configuration, safe data slicing, and cleaner execution flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Workspace Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import median_abs_deviation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "# Optional: Interactive plotting\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    HAS_PLOTLY = True\n",
    "except ImportError:\n",
    "    HAS_PLOTLY = False\n",
    "\n",
    "# Custom modules (Ensure these exist in your directory)\n",
    "import src.parsers as parsers\n",
    "import youtube_client \n",
    "\n",
    "# Pre-download NLTK data\n",
    "try:\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not download NLTK stopwords: {e}\")\n",
    "    stops = set()\n",
    "\n",
    "# Chart styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTIONS ---\n",
    "def extract_transcript_by_minutes(transcript_df, minutes):\n",
    "    \"\"\"\n",
    "    Retrieves subtitle text for specific minutes.\n",
    "    \"\"\"\n",
    "    if isinstance(minutes, (int, float)):\n",
    "        minutes = [int(minutes)]\n",
    "        \n",
    "    results = {}\n",
    "    for m in minutes:\n",
    "        start_sec = m * 60\n",
    "        end_sec = (m + 1) * 60\n",
    "        \n",
    "        mask = (transcript_df['offset_start_seconds'] >= start_sec) & \\\n",
    "               (transcript_df['offset_start_seconds'] < end_sec)\n",
    "               \n",
    "        segment = transcript_df[mask]\n",
    "        if not segment.empty:\n",
    "            text = \" \".join(segment['text'].tolist())\n",
    "            results[m] = text.strip()\n",
    "        else:\n",
    "            results[m] = \"(No speech detected)\"\n",
    "            \n",
    "    return results\n",
    "\n",
    "def convert_time(seconds, format_type=\"readable\", fps=60):\n",
    "    \"\"\"\n",
    "    Unified time conversion utility.\n",
    "    \"\"\"\n",
    "    if format_type == \"timecode\":\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        frames = int((seconds % 1) * fps)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}:{frames:02d}\"\n",
    "    elif format_type == \"readable\":\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        if hours > 0:\n",
    "            return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "        else:\n",
    "            return f\"{minutes:02d}:{secs:02d}\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format_type: {format_type}\")\n",
    "\n",
    "def get_seconds_from_tuple(tup):\n",
    "    \"\"\"Helper to convert (H, M, S) tuple to total seconds.\"\"\"\n",
    "    if not tup: return 0\n",
    "    return tup[0]*3600 + tup[1]*60 + tup[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION SECTION ===\n",
    "\n",
    "# 1. Source Settings\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=YKPHTUr3gNA\"\n",
    "YOUTUBE_ID = YOUTUBE_URL.split(\"=\")[-1].split(\"?\")[0]\n",
    "VIDEO_OUTPUT_DIR = f\"./data/{YOUTUBE_ID}\"\n",
    "os.makedirs(VIDEO_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 2. Time Slicing (Set to None to analyze full video)\n",
    "# Format: (Hours, Minutes, Seconds)\n",
    "SLICE_START = None\n",
    "SLICE_END = None\n",
    "# SLICE_START = (0, 0, 0) \n",
    "SLICE_END = (0, 50, 0)\n",
    "\n",
    "# 3. Text Cleanup (Specific corrections for this streamer/context)\n",
    "# List of tuples: (Original, Replacement)\n",
    "TEXT_REPLACEMENTS = [\n",
    "    (\"Faze\", \"Phase\"),\n",
    "    (\"&gt;&gt; \", \"\"),\n",
    "    (\"Cleo\", \"Clio\"),\n",
    "]\n",
    "\n",
    "# 4. Analysis Parameters\n",
    "TARGET_KEYWORDS = [\"lmao\", \"lol\", \"wow\", \"gg\", \"kekw\", \"wtf\", \"fuck\"]\n",
    "MIN_HIT_THRESHOLD = 5\n",
    "PEAK_THRESHOLD_MULTIPLIER = 2.0\n",
    "HIGHLIGHT_THRESHOLD_MULTIPLIER = 1.5\n",
    "\n",
    "# 5. Boundary Detection & Highlights\n",
    "BOUNDARY_START_THRESHOLD = 0.7\n",
    "BOUNDARY_END_THRESHOLD = 0.8\n",
    "HIGHLIGHT_ACTIVITY_WEIGHT = 0.7\n",
    "HIGHLIGHT_SENTIMENT_WEIGHT = 0.3\n",
    "\n",
    "# 6. Export Settings\n",
    "FPS = 60\n",
    "EDL_PADDING_MINUTES = 5\n",
    "\n",
    "# Validation\n",
    "if not YOUTUBE_URL or not YOUTUBE_ID:\n",
    "    raise ValueError(\"YouTube URL and ID must be specified\")\n",
    "if not TARGET_KEYWORDS:\n",
    "    raise ValueError(\"At least one target keyword must be specified\")\n",
    "\n",
    "print(f\"Targeting Video ID: {YOUTUBE_ID}\")\n",
    "print(f\"Analysis Slice: {SLICE_START if SLICE_START else 'Start'} to {SLICE_END if SLICE_END else 'End'}\")\n",
    "print(\"Configuration validation passed ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading",
   "metadata": {},
   "source": [
    "## 2. Download, Parse & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_parse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download source materials\n",
    "transcript_filepath = youtube_client.download_transcript(YOUTUBE_ID)\n",
    "chat_filepath = youtube_client.download_live_chat(YOUTUBE_ID)\n",
    "\n",
    "# Parse DataFrames\n",
    "parsed_transcript_df = pd.DataFrame()\n",
    "parsed_chat_df = pd.DataFrame()\n",
    "\n",
    "# Initialize critical variables to prevent Scope Errors later\n",
    "highlight_minutes = []\n",
    "start_time_seconds = 0\n",
    "\n",
    "if transcript_filepath:\n",
    "    parsed_transcript_df = parsers.parse_transcript_vtt(transcript_filepath)\n",
    "    # Apply Configured Text Replacements immediately\n",
    "    if not parsed_transcript_df.empty and TEXT_REPLACEMENTS:\n",
    "        print(f\"Applying {len(TEXT_REPLACEMENTS)} text replacements to transcript...\")\n",
    "        for original, replace in TEXT_REPLACEMENTS:\n",
    "            parsed_transcript_df['text'] = parsed_transcript_df['text'].str.replace(original, replace, regex=False)\n",
    "else:\n",
    "    print(f\"No transcript available for: {YOUTUBE_ID}\")\n",
    "\n",
    "if chat_filepath:\n",
    "    parsed_chat_df = parsers.parse_youtube_chat_json(chat_filepath)\n",
    "else:\n",
    "    print(f\"No live chat available for: {YOUTUBE_ID}\")\n",
    "\n",
    "# Display Info\n",
    "print(\"\\n--- Transcript Info ---\")\n",
    "parsed_transcript_df.info()\n",
    "print(\"\\n--- Chat Info ---\")\n",
    "parsed_chat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "time_slicing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ROBUST TIME SLICING ===\n",
    "\n",
    "# Calculate slice boundaries in seconds\n",
    "start_seconds = get_seconds_from_tuple(SLICE_START) if SLICE_START else 0\n",
    "end_seconds = get_seconds_from_tuple(SLICE_END) if SLICE_END else float('inf')\n",
    "\n",
    "start_time_seconds = start_seconds # Store for EDL export offset\n",
    "\n",
    "if SLICE_START or SLICE_END:\n",
    "    print(f\"Filtering data from {convert_time(start_seconds)} to {convert_time(end_seconds) if end_seconds != float('inf') else 'End'}...\")\n",
    "\n",
    "    # Apply Slice to Transcript\n",
    "    if not parsed_transcript_df.empty:\n",
    "        t_mask = (parsed_transcript_df['offset_start_seconds'] >= start_seconds) & \\\n",
    "                 (parsed_transcript_df['offset_start_seconds'] < end_seconds)\n",
    "        parsed_transcript_df = parsed_transcript_df[t_mask].copy()\n",
    "\n",
    "    # Apply Slice to Chat\n",
    "    if not parsed_chat_df.empty:\n",
    "        # Convert seconds to minutes for chat filtering logic (which usually relies on 'minute' column)\n",
    "        start_min = start_seconds // 60\n",
    "        end_min = end_seconds // 60\n",
    "        \n",
    "        c_mask = (parsed_chat_df['minute'] >= start_min) & \\\n",
    "                 (parsed_chat_df['minute'] < end_min)\n",
    "        parsed_chat_df = parsed_chat_df[c_mask].copy()\n",
    "\n",
    "    print(f\"Data sliced. Transcript rows: {len(parsed_transcript_df)}, Chat rows: {len(parsed_chat_df)}\")\n",
    "else:\n",
    "    print(\"Processing Full Video (No Slicing applied).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_peaks",
   "metadata": {},
   "source": [
    "## 3. General Activity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parsed_chat_df.empty:\n",
    "    # Aggregate by minute\n",
    "    messages_per_minute = parsed_chat_df.groupby(\"minute\").size().rename(\"message_count\").reset_index()\n",
    "    \n",
    "    if not messages_per_minute.empty:\n",
    "        counts = messages_per_minute[\"message_count\"].values\n",
    "        \n",
    "        # Robust Peak Detection\n",
    "        baseline = np.median(counts)\n",
    "        mad = median_abs_deviation(counts)\n",
    "        if mad == 0: mad = 1 # Prevent division by zero\n",
    "        \n",
    "        threshold = baseline + mad\n",
    "        peaks, _ = find_peaks(counts, height=threshold)\n",
    "        peak_minutes = messages_per_minute.loc[peaks, \"minute\"].tolist()\n",
    "\n",
    "        # Visualization (Interactive or Static)\n",
    "        if HAS_PLOTLY:\n",
    "            fig = px.bar(messages_per_minute, x='minute', y='message_count', \n",
    "                         title=f'Chat Volume (Peaks > {int(threshold)})', \n",
    "                         color_discrete_sequence=['skyblue'])\n",
    "            fig.add_hline(y=threshold, line_dash=\"dash\", line_color=\"salmon\", annotation_text=\"Peak Threshold\")\n",
    "            fig.show()\n",
    "        else:\n",
    "            plt.figure(figsize=(15, 6))\n",
    "            bars = plt.bar(messages_per_minute['minute'], messages_per_minute['message_count'], color='skyblue')\n",
    "            plt.axhline(threshold, color='salmon', linestyle='--', label=f'Threshold ({int(threshold)})')\n",
    "            \n",
    "            # Highlight peaks\n",
    "            for p_idx in peaks:\n",
    "                bars[p_idx].set_color('salmon')\n",
    "                \n",
    "            plt.title('Chat Volume per Minute')\n",
    "            plt.xlabel('Minute')\n",
    "            plt.ylabel('Count')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No chat messages found in the selected slice.\")\n",
    "else:\n",
    "    print(\"Skipping analysis: No chat data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_users",
   "metadata": {},
   "source": [
    "## 4. User Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gini_lorenz",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parsed_chat_df.empty:\n",
    "    user_counts = parsed_chat_df[\"author_name\"].value_counts().reset_index()\n",
    "    user_counts.columns = [\"author_name\", \"msg_count\"]\n",
    "\n",
    "    # --- Gini & Lorenz Curve ---\n",
    "    counts = user_counts[\"msg_count\"].values\n",
    "    counts_sorted = np.sort(counts)\n",
    "    n = len(counts_sorted)\n",
    "    \n",
    "    cum_counts = np.cumsum(counts_sorted)\n",
    "    if n > 0 and cum_counts[-1] > 0:\n",
    "        normalized_cum_counts = cum_counts / cum_counts[-1]\n",
    "        gini = (n + 1 - 2 * np.sum(cum_counts) / cum_counts[-1]) / n\n",
    "    else:\n",
    "        gini = 0.0\n",
    "        normalized_cum_counts = [0]\n",
    "\n",
    "    x_axis = np.linspace(0, 1, len(normalized_cum_counts))\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(x_axis, normalized_cum_counts, label=f'Gini: {gini:.3f}', linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Equality')\n",
    "    plt.title('Lorenz Curve (Chat Inequality)')\n",
    "    plt.xlabel('Cumulative % of Users')\n",
    "    plt.ylabel('Cumulative % of Messages')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Top 5 Chatters:\\n{user_counts.head(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keyword_deep_dive",
   "metadata": {},
   "source": [
    "## 5. Keyword & Transcript Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "keyword_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not parsed_chat_df.empty:\n",
    "    \n",
    "    print(\"Scanning chat for keywords...\")\n",
    "    chat_messages_lower = parsed_chat_df['message'].str.lower()\n",
    "    keyword_hits = []\n",
    "    \n",
    "    for kw in TARGET_KEYWORDS:\n",
    "        mask = chat_messages_lower.str.contains(kw, case=False, na=False)\n",
    "        if mask.any():\n",
    "            matches = parsed_chat_df[mask][['minute']].copy()\n",
    "            matches['keyword'] = kw\n",
    "            keyword_hits.extend(matches.to_dict('records'))\n",
    "    \n",
    "    df_hits = pd.DataFrame(keyword_hits)\n",
    "    \n",
    "    if not df_hits.empty:\n",
    "        pivot_df = df_hits.groupby(['minute', 'keyword']).size().unstack(fill_value=0)\n",
    "        \n",
    "        # Reindex to ensure continuous timeline\n",
    "        min_m, max_m = int(parsed_chat_df['minute'].min()), int(parsed_chat_df['minute'].max())\n",
    "        all_minutes = range(min_m, max_m + 1)\n",
    "        pivot_df = pivot_df.reindex(all_minutes, fill_value=0)\n",
    "\n",
    "        # Plot\n",
    "        if HAS_PLOTLY:\n",
    "            fig = px.bar(pivot_df, barmode='stack', title=f'Keyword Frequency: {TARGET_KEYWORDS}')\n",
    "            fig.show()\n",
    "        else:\n",
    "            pivot_df.plot(kind='bar', stacked=True, figsize=(18, 8), width=1.0, colormap='viridis')\n",
    "            plt.title(f'Keyword Frequency: {TARGET_KEYWORDS}')\n",
    "            plt.xlabel('Minute')\n",
    "            plt.xticks([]) # Hide all ticks for cleaner view\n",
    "            plt.show()\n",
    "        \n",
    "        # Context Extraction\n",
    "        minutes_meeting_threshold = pivot_df[pivot_df.sum(axis=1) >= MIN_HIT_THRESHOLD].index.tolist()\n",
    "        \n",
    "        if minutes_meeting_threshold and not parsed_transcript_df.empty:\n",
    "            print(f\"\\n--- TRANSCRIPT FOR KEYWORD SPIKES (Threshold: {MIN_HIT_THRESHOLD}+) ---\")\n",
    "            transcript_context = extract_transcript_by_minutes(parsed_transcript_df, minutes_meeting_threshold)\n",
    "            \n",
    "            for m in sorted(minutes_meeting_threshold):\n",
    "                breakdown = dict(pivot_df.loc[m][pivot_df.loc[m] > 0])\n",
    "                print(f\"\\n[Minute {m}] Keywords: {breakdown}\")\n",
    "                print(f\"{textwrap.fill(transcript_context[m], width=80, initial_indent='  ', subsequent_indent='  ')}\")\n",
    "        elif not minutes_meeting_threshold:\n",
    "            print(f\"No minutes exceeded the keyword threshold ({MIN_HIT_THRESHOLD}).\")\n",
    "    else:\n",
    "        print(\"No matches found for provided keywords.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "highlight_detection",
   "metadata": {},
   "source": [
    "## 6. Automated Highlight Detection (Sentiment + Activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_highlights",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "highlight_minutes = [] # Reset\n",
    "\n",
    "if not parsed_chat_df.empty:\n",
    "    print(\"Calculating sentiment scores (this may take a moment for large chats)...\")\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Note: For massive datasets (1M+ rows), consider batching this\n",
    "    parsed_chat_df['sentiment'] = parsed_chat_df['message'].apply(lambda msg: analyzer.polarity_scores(str(msg))['compound'])\n",
    "\n",
    "    # Aggregate\n",
    "    metrics = parsed_chat_df.groupby('minute').agg(\n",
    "        message_count=('message', 'size'),\n",
    "        avg_sentiment=('sentiment', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Normalize\n",
    "    def normalize(series):\n",
    "        return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "    if not metrics.empty:\n",
    "        metrics['norm_count'] = normalize(metrics['message_count'])\n",
    "        metrics['norm_sent'] = normalize(metrics['avg_sentiment'])\n",
    "\n",
    "        # Score Calculation\n",
    "        metrics['highlight_score'] = (HIGHLIGHT_ACTIVITY_WEIGHT * metrics['norm_count']) + \\\n",
    "                                     (HIGHLIGHT_SENTIMENT_WEIGHT * metrics['norm_sent'])\n",
    "\n",
    "        # Peak Detection\n",
    "        h_threshold = metrics['highlight_score'].mean() + (HIGHLIGHT_THRESHOLD_MULTIPLIER * metrics['highlight_score'].std())\n",
    "        peaks, _ = find_peaks(metrics['highlight_score'], height=h_threshold)\n",
    "        highlight_minutes = metrics.loc[peaks, 'minute'].tolist()\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(18, 8))\n",
    "        plt.plot(metrics['minute'], metrics['highlight_score'], label='Highlight Score', color='blue', alpha=0.6)\n",
    "        plt.scatter(metrics.loc[peaks, 'minute'], metrics.loc[peaks, 'highlight_score'], color='red', s=100, marker='*', label='Highlight')\n",
    "        plt.axhline(h_threshold, color='gray', linestyle='--', label='Threshold')\n",
    "        plt.title('Highlight Detection Score')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        if highlight_minutes and not parsed_transcript_df.empty:\n",
    "            print(f'\\n--- CONTEXT FOR {len(highlight_minutes)} DETECTED HIGHLIGHTS ---')\n",
    "            transcript_context = extract_transcript_by_minutes(parsed_transcript_df, highlight_minutes)\n",
    "            for m in sorted(highlight_minutes):\n",
    "                print(f'[Minute {m}]')\n",
    "                print(f'{textwrap.fill(transcript_context[m], width=80, initial_indent=\"  \", subsequent_indent=\"  \")}')\n",
    "    else:\n",
    "        print(\"Metrics dataframe is empty.\")\n",
    "else:\n",
    "    print(\"Chat data missing for highlight detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic_padding",
   "metadata": {},
   "source": [
    "## 7. Dynamic Padding (Smart Boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic_padding_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "#           DYNAMIC PADDING CONFIG\n",
    "# ==========================================\n",
    "BUILDUP_SEARCH_WINDOW = 10  \n",
    "WINDDOWN_SEARCH_WINDOW = 15 \n",
    "MIN_PRE_PADDING = 180  \n",
    "MIN_POST_PADDING = 120 \n",
    "ACTIVITY_THRESHOLD_MULTIPLIER = 1.5 \n",
    "DROP_OFF_CONFIRMATION_MINS = 2\n",
    "# ==========================================\n",
    "\n",
    "def get_dynamic_segments(peaks, chat_df, baseline_median):\n",
    "    segments = []\n",
    "    \n",
    "    # Get safe min/max from actual data\n",
    "    min_min = int(chat_df['minute'].min())\n",
    "    max_min = int(chat_df['minute'].max())\n",
    "    \n",
    "    # Reindex for continuous lookup\n",
    "    counts_series = chat_df.groupby('minute').size().reindex(range(min_min, max_min + 1), fill_value=0)\n",
    "    activity_threshold = baseline_median * ACTIVITY_THRESHOLD_MULTIPLIER\n",
    "\n",
    "    for peak_min in sorted(peaks):\n",
    "        peak_sec = peak_min * 60\n",
    "        \n",
    "        # --- 1. Find Start (Ramp-Up) ---\n",
    "        start_min = peak_min\n",
    "        search_start = max(min_min, peak_min - BUILDUP_SEARCH_WINDOW)\n",
    "        \n",
    "        for m in range(peak_min - 1, search_start - 1, -1):\n",
    "            if counts_series.get(m, 0) < activity_threshold:\n",
    "                start_min = m\n",
    "                break\n",
    "            start_min = m \n",
    "            \n",
    "        dynamic_start_sec = start_min * 60\n",
    "        safe_start_sec = peak_sec - MIN_PRE_PADDING\n",
    "        final_start_sec = max(min_min * 60, min(dynamic_start_sec, safe_start_sec))\n",
    "        \n",
    "        # --- 2. Find End (Drop-Off) ---\n",
    "        end_min = peak_min\n",
    "        search_end = min(max_min, peak_min + WINDDOWN_SEARCH_WINDOW)\n",
    "        quiet_streak = 0\n",
    "        \n",
    "        for m in range(peak_min + 1, search_end + 1):\n",
    "            if counts_series.get(m, 0) < activity_threshold:\n",
    "                quiet_streak += 1\n",
    "            else:\n",
    "                quiet_streak = 0\n",
    "            \n",
    "            if quiet_streak >= DROP_OFF_CONFIRMATION_MINS:\n",
    "                end_min = m - quiet_streak + 1\n",
    "                break\n",
    "            end_min = m\n",
    "\n",
    "        dynamic_end_sec = (end_min + 1) * 60\n",
    "        safe_end_sec = peak_sec + MIN_POST_PADDING\n",
    "        final_end_sec = max(dynamic_end_sec, safe_end_sec)\n",
    "        \n",
    "        segments.append((int(final_start_sec), int(final_end_sec)))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def merge_segments(segments):\n",
    "    if not segments: return []\n",
    "    segments.sort(key=lambda x: x[0])\n",
    "    merged = []\n",
    "    current_start, current_end = segments[0]\n",
    "    \n",
    "    for next_start, next_end in segments[1:]:\n",
    "        if next_start <= current_end + 10: # Merge if gap is small\n",
    "            current_end = max(current_end, next_end)\n",
    "        else:\n",
    "            merged.append((current_start, current_end))\n",
    "            current_start, current_end = next_start, next_end\n",
    "            \n",
    "    merged.append((current_start, current_end))\n",
    "    return merged\n",
    "\n",
    "# Execution\n",
    "dynamic_time_ranges = []\n",
    "if highlight_minutes and not parsed_chat_df.empty:\n",
    "    slice_min = int(parsed_chat_df['minute'].min())\n",
    "    slice_max = int(parsed_chat_df['minute'].max())\n",
    "    \n",
    "    counts_in_slice = parsed_chat_df.groupby('minute').size().reindex(range(slice_min, slice_max + 1), fill_value=0)\n",
    "    median_rate = counts_in_slice.median()\n",
    "    \n",
    "    print(f\"Baseline Rate: {median_rate:.1f} msgs/min | Threshold: {median_rate * ACTIVITY_THRESHOLD_MULTIPLIER:.1f}\")\n",
    "    \n",
    "    raw_segments = get_dynamic_segments(highlight_minutes, parsed_chat_df, median_rate)\n",
    "    dynamic_time_ranges = merge_segments(raw_segments)\n",
    "    \n",
    "    print(f\"\\nGenerated {len(dynamic_time_ranges)} optimized segments:\")\n",
    "    for i, (start, end) in enumerate(dynamic_time_ranges, 1):\n",
    "        print(f\"{i}. {convert_time(start)} -> {convert_time(end)} (Duration: {convert_time(end-start)})\")\n",
    "else:\n",
    "    print(\"Skipping Dynamic Padding: No highlights found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc274120",
   "metadata": {},
   "source": [
    "# 8. Output\n",
    "- edl for davinci resolve\n",
    "- export srt file from transcript dataframe\n",
    "- download video clips from highlights\n",
    "- export csv file from chat dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edl_export",
   "metadata": {},
   "outputs": [],
   "source": [
    "#               EDL EXPORT\n",
    "# ==========================================\n",
    "# If SOURCE_MATCHES_SLICE is True, the EDL assumes the source video starts at 00:00 relative to the slice.\n",
    "# If False, it assumes source video is the full original stream.\n",
    "SOURCE_MATCHES_SLICE = True\n",
    "\n",
    "OUTPUT_EDL_PATH = f\"{VIDEO_OUTPUT_DIR}/highlights_{YOUTUBE_ID}.edl\"\n",
    "\n",
    "def seconds_to_timecode(seconds, fps=FPS):\n",
    "    return convert_time(seconds, \"timecode\", fps)\n",
    "\n",
    "def generate_edl(ranges, output_filename, offset_seconds):\n",
    "    if not ranges:\n",
    "        print(\"No ranges to export.\")\n",
    "        return\n",
    "\n",
    "    # Offset Logic\n",
    "    # If the user has a trimmed clip, we subtract the start_time_seconds from the absolute time\n",
    "    # to get the relative time in the clip.\n",
    "    calc_offset = offset_seconds if SOURCE_MATCHES_SLICE else 0\n",
    "    \n",
    "    mode_str = \"Trimmed Clip\" if SOURCE_MATCHES_SLICE else \"Full Stream\"\n",
    "    print(f\"Generating EDL in '{mode_str}' mode. Offset: {calc_offset}s\")\n",
    "\n",
    "    edl_lines = [\n",
    "        f\"TITLE: Highlights_{YOUTUBE_ID}\",\n",
    "        \"FCM: NON-DROP FRAME\",\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    current_timeline_time = 0\n",
    "    \n",
    "    for i, (abs_start, abs_end) in enumerate(ranges, 1):\n",
    "        duration_sec = abs_end - abs_start\n",
    "        \n",
    "        src_in = max(0, abs_start - calc_offset)\n",
    "        src_out = max(0, abs_end - calc_offset)\n",
    "        \n",
    "        source_start_tc = seconds_to_timecode(src_in)\n",
    "        source_end_tc = seconds_to_timecode(src_out)\n",
    "        timeline_start_tc = seconds_to_timecode(current_timeline_time)\n",
    "        timeline_end_tc = seconds_to_timecode(current_timeline_time + duration_sec)\n",
    "        \n",
    "        clip_name = f\"HIGHLIGHT_{i:03d}\"\n",
    "        edl_lines.append(f\"{i:03d}  {clip_name}     V     C        {source_start_tc} {source_end_tc} {timeline_start_tc} {timeline_end_tc}\")\n",
    "        edl_lines.append(f\"* FROM CLIP NAME: {clip_name}\")\n",
    "        edl_lines.append(f\"* ABSOLUTE STREAM TIME: {convert_time(abs_start)} - {convert_time(abs_end)}\")\n",
    "        edl_lines.append(\"\")\n",
    "\n",
    "        current_timeline_time += duration_sec\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(edl_lines))\n",
    "    \n",
    "    print(f\"✓ Saved EDL to: {output_filename}\")\n",
    "\n",
    "# Run\n",
    "if dynamic_time_ranges:\n",
    "    generate_edl(dynamic_time_ranges, OUTPUT_EDL_PATH, start_time_seconds)\n",
    "else:\n",
    "    print(\"No dynamic ranges available for export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_srt(df, output_path, ref_start_seconds=0, ref_end_seconds=None):\n",
    "    \"\"\"\n",
    "    Convert transcript DataFrame to SRT Format with relative timing and clamping.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the transcript rows.\n",
    "        output_path: Destination file path.\n",
    "        ref_start_seconds: The absolute start time of the clip. \n",
    "                           Subtitles will be shifted so this timestamp becomes 00:00:00.\n",
    "        ref_end_seconds: The absolute end time of the clip. \n",
    "                         Subtitles extending past this will be clamped/cut off.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return False\n",
    "        \n",
    "    def seconds_to_srt_time(seconds):\n",
    "        # Helper to format seconds to HH:MM:SS,mmm\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        milliseconds = int((seconds % 1) * 1000)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}\"\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            counter = 1\n",
    "            for _, row in df.iterrows():\n",
    "                # 1. Calculate Absolute Times\n",
    "                abs_start = row['offset_start_seconds']\n",
    "                abs_end = row['offset_end_seconds']\n",
    "\n",
    "                # 2. Skip if completely out of bounds (redundant if filtered, but safe)\n",
    "                if ref_end_seconds and abs_start >= ref_end_seconds:\n",
    "                    continue\n",
    "                if abs_end <= ref_start_seconds:\n",
    "                    continue\n",
    "\n",
    "                # 3. Calculate Relative Times (Shifted)\n",
    "                rel_start = abs_start - ref_start_seconds\n",
    "                rel_end = abs_end - ref_start_seconds\n",
    "\n",
    "                # 4. Clamp Boundaries\n",
    "                # If subtitle starts before clip, set to 0\n",
    "                if rel_start < 0: \n",
    "                    rel_start = 0\n",
    "                \n",
    "                # If subtitle ends after clip, cap it at the clip duration\n",
    "                if ref_end_seconds:\n",
    "                    clip_duration = ref_end_seconds - ref_start_seconds\n",
    "                    if rel_end > clip_duration:\n",
    "                        rel_end = clip_duration\n",
    "\n",
    "                # 5. Write to File\n",
    "                # Only write if there is a valid duration (start < end)\n",
    "                if rel_end > rel_start:\n",
    "                    start_str = seconds_to_srt_time(rel_start)\n",
    "                    end_str = seconds_to_srt_time(rel_end)\n",
    "                    \n",
    "                    f.write(f\"{counter}\\n\")\n",
    "                    f.write(f\"{start_str} --> {end_str}\\n\")\n",
    "                    f.write(f\"{row['text']}\\n\\n\")\n",
    "                    counter += 1\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting SRT {output_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db15b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Toggle to actually download video (False = Generate SRT/CSV only)\n",
    "VIDEO_CLIP_DOWNLOAD = True\n",
    "# True: Downloads separate video files for each highlight.\n",
    "# False: Downloads one single video from the start of the first highlight to the end of the last.\n",
    "DOWNLOAD_IN_SECTIONS = False\n",
    "# Overwrite files if they already exist?\n",
    "OVERWRITE_EXISTING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "#        EXPORT CONFIGURATION & SETUP\n",
    "# ==========================================\n",
    "import os\n",
    "\n",
    "# --- Core Export Logic ---\n",
    "def process_export_job(job_name, start_sec, end_sec, output_dir):\n",
    "    \"\"\"\n",
    "    Handles the generation of Video, SRT, and CSV for a specific time range.\n",
    "    Returns a summary string of actions taken.\n",
    "    \"\"\"\n",
    "    actions_taken = []\n",
    "    \n",
    "    # 1. Define File Paths\n",
    "    video_path = os.path.join(output_dir, f\"{job_name}.mp4\")\n",
    "    srt_path = os.path.join(output_dir, f\"{job_name}.srt\")\n",
    "    csv_path = os.path.join(output_dir, f\"{job_name}_chat.csv\")\n",
    "\n",
    "    # 2. Video Download\n",
    "    if VIDEO_CLIP_DOWNLOAD:\n",
    "        if not os.path.exists(video_path) or OVERWRITE_EXISTING:\n",
    "            try:\n",
    "                # Assuming youtube_client accepts a list of tuples for sections\n",
    "                # We pass just one section for this specific job\n",
    "                time_range = [(convert_time(start_sec), convert_time(end_sec))]\n",
    "                \n",
    "                youtube_client.download_video(\n",
    "                    YOUTUBE_ID, \n",
    "                    output_dir=output_dir, \n",
    "                    video_name=job_name, \n",
    "                    download_sections=time_range\n",
    "                )\n",
    "                actions_taken.append(\"Video Downloaded\")\n",
    "            except Exception as e:\n",
    "                print(f\"  [!] Video Error: {e}\")\n",
    "        else:\n",
    "            actions_taken.append(\"Video Exists (Skipped)\")\n",
    "\n",
    "    # 3. SRT Generation\n",
    "    # We use the previously defined 'dataframe_to_srt'\n",
    "    if not parsed_transcript_df.empty:\n",
    "        # Filter transcript to the job's range\n",
    "        t_mask = (parsed_transcript_df['offset_end_seconds'] > start_sec) & \\\n",
    "                 (parsed_transcript_df['offset_start_seconds'] < end_sec)\n",
    "        job_transcript = parsed_transcript_df[t_mask].copy()\n",
    "        \n",
    "        if not job_transcript.empty:\n",
    "            success = dataframe_to_srt(\n",
    "                job_transcript, \n",
    "                srt_path, \n",
    "                ref_start_seconds=start_sec, # 00:00 in SRT will equal start_sec\n",
    "                ref_end_seconds=end_sec\n",
    "            )\n",
    "            if success: actions_taken.append(\"SRT Generated\")\n",
    "    \n",
    "    # 4. Chat CSV Export\n",
    "    if not parsed_chat_df.empty:\n",
    "        # Filter chat to the job's range\n",
    "        c_mask = (parsed_chat_df['offset_seconds'] >= start_sec) & \\\n",
    "                 (parsed_chat_df['offset_seconds'] < end_sec)\n",
    "        job_chat = parsed_chat_df[c_mask].copy()\n",
    "        \n",
    "        if not job_chat.empty:\n",
    "            # Normalize time relative to the clip start\n",
    "            job_chat['relative_seconds'] = job_chat['offset_seconds'] - start_sec\n",
    "            \n",
    "            # Select and rename columns for clean output\n",
    "            export_cols = {\n",
    "                'relative_seconds': 'time_offset',\n",
    "                'author_name': 'user',\n",
    "                'message': 'message'\n",
    "            }\n",
    "            # Include superchat if available\n",
    "            if 'superchat_amount' in job_chat.columns:\n",
    "                export_cols['superchat_amount'] = 'amount'\n",
    "                \n",
    "            csv_data = job_chat.rename(columns=export_cols)[export_cols.values()]\n",
    "            csv_data['time_offset'] = csv_data['time_offset'].round(2)\n",
    "            \n",
    "            csv_data.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "            actions_taken.append(f\"Chat CSV ({len(job_chat)} msgs)\")\n",
    "\n",
    "    return \", \".join(actions_taken) if actions_taken else \"No actions (Data missing or files exist)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "#             BATCH PROCESSING\n",
    "# ==========================================\n",
    "\n",
    "if 'dynamic_time_ranges' in locals() and dynamic_time_ranges:\n",
    "    \n",
    "    export_jobs = []\n",
    "\n",
    "    # --- Scenario A: Download Sections (Separate Clips) ---\n",
    "    if DOWNLOAD_IN_SECTIONS:\n",
    "        print(f\"Mode: Multi-Section Export ({len(dynamic_time_ranges)} clips)\")\n",
    "        for i, (start, end) in enumerate(dynamic_time_ranges, 1):\n",
    "            export_jobs.append({\n",
    "                \"name\": f\"HIGHLIGHT_{i:03d}\",\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"desc\": f\"Clip {i}\"\n",
    "            })\n",
    "\n",
    "    # --- Scenario B: Download Combined (Single Range) ---\n",
    "    else:\n",
    "        # Determine the full span from the first highlight start to the last highlight end\n",
    "        full_start = start_seconds\n",
    "        full_end = end_seconds\n",
    "\n",
    "        print(f\"Mode: Combined Export (Span: {convert_time(full_start)} - {convert_time(full_end)})\")\n",
    "        export_jobs.append({\n",
    "            \"name\": f\"FULL_SESSION_{YOUTUBE_ID}\",\n",
    "            \"start\": full_start,\n",
    "            \"end\": full_end,\n",
    "            \"desc\": \"Full Highlight Span\"\n",
    "        })\n",
    "\n",
    "    # --- Execute Jobs ---\n",
    "    print(f\"\\nProcessing {len(export_jobs)} job(s)...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, job in enumerate(export_jobs, 1):\n",
    "        print(f\"[{i}/{len(export_jobs)}] {job['desc']}...\", end=\" \", flush=True)\n",
    "        \n",
    "        try:\n",
    "            result_summary = process_export_job(\n",
    "                job_name=job['name'],\n",
    "                start_sec=job['start'],\n",
    "                end_sec=job['end'],\n",
    "                output_dir=VIDEO_OUTPUT_DIR\n",
    "            )\n",
    "            print(f\"DONE. [{result_summary}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED.\\n    Error: {str(e)}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Export Complete.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Export: No 'dynamic_time_ranges' found. Please run the analysis cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcript-archiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
