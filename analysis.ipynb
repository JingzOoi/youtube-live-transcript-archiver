{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# Stream Analysis Flow\n",
        "This notebook processes YouTube transcripts and live chat logs to analyze engagement, spikes, and keywords."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup",
      "metadata": {},
      "source": [
        "## 1. Workspace Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import find_peaks\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import textwrap\n",
        "\n",
        "# Custom module\n",
        "import parsers\n",
        "import youtube_client # Ensure this file exists in your directory\n",
        "\n",
        "# Pre-download NLTK data\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Chart styling\n",
        "plt.style.use('seaborn-v0_8-darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "helper_functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- HELPER FUNCTIONS ---\n",
        "def extract_transcript_by_minutes(transcript_df, minutes):\n",
        "    \"\"\"\n",
        "    Retrieves subtitle text for specific minutes.\n",
        "    \n",
        "    Args:\n",
        "        transcript_df (pd.DataFrame): The dataframe containing transcript data.\n",
        "        minutes (list or int): A single minute (int) or list of minutes to retrieve.\n",
        "        \n",
        "    Returns:\n",
        "        dict: A dictionary where key is the minute (int) and value is the text (str).\n",
        "    \"\"\"\n",
        "    if isinstance(minutes, (int, float)):\n",
        "        minutes = [int(minutes)]\n",
        "        \n",
        "    results = {}\n",
        "    for m in minutes:\n",
        "        start_sec = m * 60\n",
        "        end_sec = (m + 1) * 60\n",
        "        \n",
        "        # Filter rows that start within this minute\n",
        "        mask = (transcript_df['offset_start_seconds'] >= start_sec) & \\\n",
        "               (transcript_df['offset_start_seconds'] < end_sec)\n",
        "               \n",
        "        segment = transcript_df[mask]\n",
        "        if not segment.empty:\n",
        "            # Join text and clean up extra spaces\n",
        "            text = \" \".join(segment['text'].tolist())\n",
        "            results[m] = text.strip()\n",
        "        else:\n",
        "            results[m] = \"(No speech detected)\"\n",
        "            \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=p8sR5q7OGBk\"\n",
        "YT_ID = YOUTUBE_URL.split(\"=\")[-1].split(\"?\")[0]\n",
        "\n",
        "print(f\"Targeting Video ID: {YT_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loading",
      "metadata": {},
      "source": [
        "## 2. Download & Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "download_parse",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download source materials\n",
        "transcript_filepath = youtube_client.download_transcript(YT_ID)\n",
        "chat_filepath = youtube_client.download_live_chat(YT_ID)\n",
        "\n",
        "# Parse DataFrames\n",
        "parsed_transcript_df = pd.DataFrame()\n",
        "parsed_chat_df = pd.DataFrame()\n",
        "\n",
        "if transcript_filepath:\n",
        "    parsed_transcript_df = parsers.parse_transcript_vtt(transcript_filepath)\n",
        "else:\n",
        "    print(f\"No transcript available for: {YT_ID}\")\n",
        "\n",
        "if chat_filepath:\n",
        "    parsed_chat_df = parsers.parse_live_chat_json(chat_filepath)\n",
        "else:\n",
        "    print(f\"No live chat available for: {YT_ID}\")\n",
        "\n",
        "# Display Info\n",
        "print(\"\\n--- Transcript Info ---\")\n",
        "parsed_transcript_df.info()\n",
        "print(\"\\n--- Chat Info ---\")\n",
        "parsed_chat_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693dab9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "replace_dict = [\n",
        "    (\"Faze\", \"Phase\"),\n",
        "    (\"&gt;&gt; \", \"\"),\n",
        "    (\"Cleo\", \"Clio\"),\n",
        "]\n",
        "\n",
        "for original, replace in replace_dict:\n",
        "    parsed_transcript_df['text'] = parsed_transcript_df['text'].str.replace(original, replace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03242b85",
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = (1, 14, 0) # in h, m\n",
        "end_time = (3, 40, 0)\n",
        "# change to seconds, and reshape the dfs to only preserve the rows within the minutes\n",
        "start_time_seconds = start_time[0]*60*60 + start_time[1]*60 + end_time[2]\n",
        "end_time_seconds = end_time[0]*60*60 + end_time[1]*60 + end_time[2]\n",
        "start_time_minute = start_time[0]*60 + start_time[1]\n",
        "end_time_minute = end_time[0]*60 + end_time[1]\n",
        "\n",
        "# TODO: reshape dfs\n",
        "transcript_mask = (parsed_transcript_df['offset_start_seconds'] >= start_time_seconds) & \\\n",
        "        (parsed_transcript_df['offset_start_seconds'] < end_time_seconds)\n",
        "parsed_transcript_df = parsed_transcript_df[transcript_mask]\n",
        "\n",
        "chat_mask = (parsed_chat_df['minute'] >= start_time_minute) & \\\n",
        "        (parsed_chat_df['minute'] < end_time_minute)\n",
        "parsed_chat_df = parsed_chat_df[chat_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analysis_peaks",
      "metadata": {},
      "source": [
        "## 3. General Activity Analysis\n",
        "Identify moments where chat volume spikes significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "calc_metrics",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not parsed_chat_df.empty:\n",
        "    # Aggregate by minute\n",
        "    messages_per_minute = parsed_chat_df.groupby(\"minute\").size().rename(\"message_count\").reset_index()\n",
        "    \n",
        "    # Peak Detection\n",
        "    counts = messages_per_minute[\"message_count\"].values\n",
        "    # Peak threshold: Mean + 2 Standard Deviations\n",
        "    threshold = counts.mean() + (2 * counts.std())\n",
        "    peaks, _ = find_peaks(counts, height=threshold)\n",
        "    peak_minutes = messages_per_minute.loc[peaks, \"minute\"].tolist()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    bars = plt.bar(messages_per_minute['minute'], messages_per_minute['message_count'], \n",
        "                   color='skyblue', label='Messages/Min')\n",
        "\n",
        "    # Highlight spikes\n",
        "    for minute in peak_minutes:\n",
        "        idx = messages_per_minute[messages_per_minute['minute'] == minute].index\n",
        "        if not idx.empty:\n",
        "            bars[idx[0]].set_color('salmon')\n",
        "\n",
        "    plt.title(f'Chat Volume per Minute (Spikes > {int(threshold)} msgs)', fontsize=14)\n",
        "    plt.xlabel('Minute Offset')\n",
        "    plt.ylabel('Message Count')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show context for peaks using the new helper function\n",
        "    if not parsed_transcript_df.empty and peak_minutes:\n",
        "        print(f\"\\n--- CONTEXT FOR HIGH TRAFFIC MOMENTS (>{int(threshold)} msgs) ---\")\n",
        "        transcript_context = extract_transcript_by_minutes(parsed_transcript_df, peak_minutes)\n",
        "        \n",
        "        for m in sorted(peak_minutes):\n",
        "            print(f\"\\n[Minute {m}] {messages_per_minute.loc[messages_per_minute['minute'] == m, 'message_count'].values[0]} msgs\")\n",
        "            print(f\"{textwrap.fill(transcript_context[m], width=80, initial_indent='  ', subsequent_indent='  ')}\")\n",
        "else:\n",
        "    print(\"Skipping analysis: No chat data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analysis_users",
      "metadata": {},
      "source": [
        "## 4. User Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gini_lorenz",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not parsed_chat_df.empty:\n",
        "    # Calculate Counts\n",
        "    user_counts = parsed_chat_df[\"author_name\"].value_counts().reset_index()\n",
        "    user_counts.columns = [\"author_name\", \"msg_count\"]\n",
        "\n",
        "    # --- Gini & Lorenz Curve ---\n",
        "    counts = user_counts[\"msg_count\"].values\n",
        "    counts_sorted = np.sort(counts)\n",
        "    n = len(counts_sorted)\n",
        "    \n",
        "    # Lorenz calc\n",
        "    cum_counts = np.cumsum(counts_sorted)\n",
        "    normalized_cum_counts = cum_counts / cum_counts[-1]\n",
        "    \n",
        "    # Gini calc\n",
        "    # Area under Lorenz curve is sum(cum_counts) / total_sum / n roughly, \n",
        "    # but standard formula is (2 * Area_between_line_equality_and_lorenz)\n",
        "    gini = (n + 1 - 2 * np.sum(cum_counts) / cum_counts[-1]) / n\n",
        "\n",
        "    x_axis = np.linspace(0, 1, len(normalized_cum_counts))\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(x_axis, normalized_cum_counts, label=f'Gini: {gini:.3f}', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Equality')\n",
        "    plt.title('Lorenz Curve (Chat Inequality)')\n",
        "    plt.xlabel('Cumulative % of Users')\n",
        "    plt.ylabel('Cumulative % of Messages')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Top 5 Chatters:\\n{user_counts.head(5)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "keyword_deep_dive",
      "metadata": {},
      "source": [
        "## 5. Keyword & Transcript Deep Dive (New Feature)\n",
        "Define a list of keywords to see where they appear in chat, and cross-reference with what was being said in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "keyword_viz",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- USER CONFIG ---\n",
        "TARGET_KEYWORDS = [\"lmao\", \"lol\", \"wow\", \"gg\", \"kekw\", \"wtf\", \"fuck\"] \n",
        "MIN_HIT_THRESHOLD = 5 # Only show subtitles if keywords appear > this many times in a minute\n",
        "# ------------------\n",
        "\n",
        "if not parsed_chat_df.empty and not parsed_transcript_df.empty:\n",
        "    \n",
        "    # 1. Filter chat for keywords\n",
        "    keyword_hits = []\n",
        "    \n",
        "    print(\"Scanning chat for keywords...\")\n",
        "    for idx, row in parsed_chat_df.iterrows():\n",
        "        msg_lower = str(row['message']).lower()\n",
        "        minute = row['minute']\n",
        "        \n",
        "        for kw in TARGET_KEYWORDS:\n",
        "            if kw in msg_lower:\n",
        "                keyword_hits.append({\n",
        "                    'minute': minute,\n",
        "                    'keyword': kw\n",
        "                })\n",
        "    \n",
        "    df_hits = pd.DataFrame(keyword_hits)\n",
        "    \n",
        "    if not df_hits.empty:\n",
        "        # 2. Pivot for Stacked Bar Chart\n",
        "        pivot_df = df_hits.groupby(['minute', 'keyword']).size().unstack(fill_value=0)\n",
        "        \n",
        "        all_minutes = range(int(parsed_chat_df['minute'].min()), int(parsed_chat_df['minute'].max()) + 1)\n",
        "        pivot_df = pivot_df.reindex(all_minutes, fill_value=0)\n",
        "\n",
        "        # 3. Plot\n",
        "        ax = pivot_df.plot(kind='bar', stacked=True, figsize=(18, 8), width=1.0, colormap='viridis')\n",
        "        \n",
        "        ticks = ax.xaxis.get_ticklocs()\n",
        "        ticklabels = [l.get_text() for l in ax.xaxis.get_ticklabels()]\n",
        "        ax.xaxis.set_ticks(ticks[::10])\n",
        "        ax.xaxis.set_ticklabels(ticklabels[::10], rotation=0)\n",
        "        \n",
        "        plt.title(f'Keyword Frequency per Minute: {TARGET_KEYWORDS}', fontsize=16)\n",
        "        plt.xlabel('Minute Offset')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.legend(title='Keywords')\n",
        "        plt.show()\n",
        "        \n",
        "        # 4. Context Extraction (Subtitles)\n",
        "        minutes_meeting_threshold_mask = (pivot_df >= MIN_HIT_THRESHOLD).any(axis=1)\n",
        "        \n",
        "        \n",
        "        # Sort the significant ones by activity\n",
        "        top_minutes = pivot_df[minutes_meeting_threshold_mask].index.tolist()\n",
        "        \n",
        "        if top_minutes:\n",
        "            print(f\"\\n--- TRANSCRIPT CONTEXT FOR TOP SPIKES (Threshold: {MIN_HIT_THRESHOLD}+ hits) ---\")\n",
        "            \n",
        "            # --- USE NEW HELPER FUNCTION HERE ---\n",
        "            transcript_context = extract_transcript_by_minutes(parsed_transcript_df, top_minutes)\n",
        "            \n",
        "            for m in sorted(top_minutes):\n",
        "                breakdown = dict(pivot_df.loc[m][pivot_df.loc[m] > 0])\n",
        "                print(f\"\\n[Minute {m}] Keywords: {breakdown}\")\n",
        "                print(f\"{textwrap.fill(transcript_context[m], width=80, initial_indent='  ', subsequent_indent='  ')}\")\n",
        "        else:\n",
        "            print(f\"\\nNo minutes found with more than {MIN_HIT_THRESHOLD} keyword hits. Try lowering the threshold.\")\n",
        "                \n",
        "    else:\n",
        "        print(\"No matches found for the provided keywords.\")\n",
        "else:\n",
        "    print(\"Chat or Transcript data missing, cannot run Deep Dive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b999be08",
      "metadata": {},
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "if not parsed_chat_df.empty:\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # 1. Calculate sentiment for each chat message\n",
        "    parsed_chat_df['sentiment'] = parsed_chat_df['message'].apply(lambda msg: analyzer.polarity_scores(msg)['compound'])\n",
        "\n",
        "    # 2. Aggregate metrics per minute\n",
        "    messages_per_minute = parsed_chat_df.groupby('minute').agg(\n",
        "        message_count=('message', 'size'),\n",
        "        avg_sentiment=('sentiment', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    # 3. Calculate a highlight score\n",
        "    # We normalize message count and sentiment to combine them.\n",
        "    # A highlight is a combination of high activity and positive sentiment.\n",
        "    msg_count_norm = (messages_per_minute['message_count'] - messages_per_minute['message_count'].min()) / (messages_per_minute['message_count'].max() - messages_per_minute['message_count'].min())\n",
        "    sentiment_norm = (messages_per_minute['avg_sentiment'] - messages_per_minute['avg_sentiment'].min()) / (messages_per_minute['avg_sentiment'].max() - messages_per_minute['avg_sentiment'].min())\n",
        "\n",
        "    # Combine metrics. Adjust weighting as needed.\n",
        "    messages_per_minute['highlight_score'] = (0.7 * msg_count_norm) + (0.3 * sentiment_norm)\n",
        "\n",
        "    # 4. Find peaks in the highlight score\n",
        "    highlight_threshold = messages_per_minute['highlight_score'].mean() + 1.5 * messages_per_minute['highlight_score'].std()\n",
        "    peaks, _ = find_peaks(messages_per_minute['highlight_score'], height=highlight_threshold)\n",
        "    highlight_minutes = messages_per_minute.loc[peaks, 'minute'].tolist()\n",
        "\n",
        "    # 5. Visualization\n",
        "    plt.figure(figsize=(18, 8))\n",
        "    plt.plot(messages_per_minute['minute'], messages_per_minute['highlight_score'], label='Highlight Score', color='blue', zorder=2)\n",
        "    plt.scatter(messages_per_minute.loc[peaks, 'minute'], messages_per_minute.loc[peaks, 'highlight_score'], color='red', s=100, label='Detected Highlights', zorder=5, marker='*')\n",
        "    plt.axhline(y=highlight_threshold, color='gray', linestyle='--', label='Highlight Threshold')\n",
        "    plt.title('Automated Highlight Detection', fontsize=16)\n",
        "    plt.xlabel('Minute of Stream')\n",
        "    plt.ylabel('Calculated Highlight Score')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 6. Print context for highlights\n",
        "    if not parsed_transcript_df.empty and highlight_minutes:\n",
        "        print(f'--- CONTEXT FOR DETECTED HIGHLIGHTS ---')\n",
        "        for minute in sorted(highlight_minutes):\n",
        "            start_sec = minute * 60\n",
        "            end_sec = (minute + 1) * 60\n",
        "            mask = (parsed_transcript_df['offset_start_seconds'] >= start_sec) & (parsed_transcript_df['offset_start_seconds'] < end_sec)\n",
        "            segment = parsed_transcript_df[mask]\n",
        "            transcript_text = \" \".join(segment['text'].tolist()).strip() if not segment.empty else \"(No speech detected)\"\n",
        "            print(f'[Minute {minute}]')\n",
        "            print(f'  Streamer said: {textwrap.fill(transcript_text, width=80, initial_indent=\"    \", subsequent_indent=\"    \")}')\n",
        "else:\n",
        "    print('Chat data is not available, cannot perform highlight detection.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "topic_detection",
      "metadata": {},
      "source": [
        "## 6. Topic Detection (New Feature)\n",
        "Automatically detect topic changes and generate timestamps without using LLMs. Uses multiple methods including keyword detection, TF-IDF clustering, and vocabulary change analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "topic_detection_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import topic detection module\n",
        "import topic_detector\n",
        "\n",
        "# --- TOPIC DETECTION CONFIGURATION ---\n",
        "# Choose which methods to use: 'keyword', 'tfidf', 'vocabulary', or combinations\n",
        "TOPIC_METHODS = ['keyword', 'tfidf', 'vocabulary']  # Try different combinations\n",
        "MIN_CONFIDENCE = 0.3  # Minimum confidence threshold\n",
        "SHOW_TOPICS = 10  # Maximum number of topics to display\n",
        "CONTEXT_MINUTES = 2  # Minutes of context to show around each topic\n",
        "\n",
        "if not parsed_transcript_df.empty:\n",
        "    print(\"=== TOPIC DETECTION ANALYSIS ===\")\n",
        "    print(f\"Transcript duration: {parsed_transcript_df['offset_start_seconds'].max() / 60:.1f} minutes\")\n",
        "    print(f\"Total transcript entries: {len(parsed_transcript_df)}\")\n",
        "    print()\n",
        "    \n",
        "    # Test different method combinations\n",
        "    for method_combo in TOPIC_METHODS:\n",
        "        if isinstance(method_combo, str):\n",
        "            methods = [method_combo]\n",
        "        else:\n",
        "            methods = method_combo\n",
        "        \n",
        "        print(f\"\\n--- Using methods: {', '.join(methods)} ---\")\n",
        "        \n",
        "        # Generate topic timestamps\n",
        "        topics_df = topic_detector.generate_topic_timestamps(parsed_transcript_df, methods=methods)\n",
        "        \n",
        "        if topics_df.empty:\n",
        "            print(\"No topics detected with current methods.\")\n",
        "            continue\n",
        "        \n",
        "        # Display results\n",
        "        print(f\"Detected {len(topics_df)} topic changes:\")\n",
        "        \n",
        "        # Show top topics with context\n",
        "        top_topics = topics_df.head(SHOW_TOPICS)\n",
        "        if not top_topics.empty:\n",
        "            topic_summaries = topic_detector.extract_topic_summary(parsed_transcript_df, top_topics)\n",
        "            \n",
        "            for i, summary in enumerate(topic_summaries, 1):\n",
        "                print(f\"\\n{i+1}. {summary['timestamp_readable']} (confidence: {summary['confidence']:.2f}, method: {summary['method']})\")\n",
        "                print(f\"   Keywords: {', '.join(summary['keywords'][:5])}\")\n",
        "                print(f\"   Preview: {summary['text_preview'][:100]}...\")\n",
        "                print(f\"   Context: {summary['full_context'][:200]}...\")\n",
        "        \n",
        "        # Optional: Show all topics in a table format\n",
        "        if len(topics_df) > SHOW_TOPICS:\n",
        "            print(f\"\\n... and {len(topics_df) - SHOW_TOPICS} more topics detected\")\n",
        "            print(\"\\nFull topic table:\")\n",
        "            display_cols = ['timestamp_readable', 'confidence', 'method', 'text']\n",
        "            print(topics_df[display_cols].head(SHOW_TOPICS + 5).to_string(index=False))\n",
        "else:\n",
        "    print(\"No transcript data available for topic detection.\")\n",
        "\n",
        "print(\"\\n=== Topic Detection Complete ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "davinci_export",
      "metadata": {},
      "source": [
        "## 7. DaVinci Resolve XML Export\n",
        "Generate a DaVinci Resolve compatible XML file for the detected highlights with 5-minute padding and overlap merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "davinci_xml_export",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying offset of 4440 seconds (74:00) from reshaping\n",
            "Generated EDL: highlights_p8sR5q7OGBk.edl\n",
            "Exported 6 highlight segments:\n",
            "  1. 71:00 - 86:00 (duration: 15:00)\n",
            "  2. 87:00 - 100:00 (duration: 13:00)\n",
            "  3. 115:00 - 125:00 (duration: 10:00)\n",
            "  4. 150:00 - 160:00 (duration: 10:00)\n",
            "  5. 189:00 - 199:00 (duration: 10:00)\n",
            "  6. 205:00 - 217:00 (duration: 12:00)\n",
            "\n",
            "EDL file saved as: highlights_p8sR5q7OGBk.edl\n",
            "Import this file into DaVinci Resolve using File > Import Timeline > EDL...\n",
            "Or import into other NLEs like Premiere Pro, Final Cut Pro, etc.\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "def generate_edl(highlight_minutes, output_filename=\"highlights.edl\", padding_minutes=5, fps=30, offset_seconds=0):\n",
        "    \"\"\"\n",
        "    Generate EDL (Edit Decision List) for highlights.\n",
        "    \n",
        "    Args:\n",
        "        highlight_minutes (list): List of minute offsets for highlights\n",
        "        output_filename (str): Output EDL filename\n",
        "        padding_minutes (int): Minutes to pad before and after each highlight\n",
        "        fps (int): Frames per second for timecode calculation\n",
        "    \"\"\"\n",
        "    if not highlight_minutes:\n",
        "        print(\"No highlights to export.\")\n",
        "        return\n",
        "    \n",
        "    # Sort highlights\n",
        "    highlight_minutes = sorted(highlight_minutes)\n",
        "    \n",
        "    # Create time ranges with padding\n",
        "    time_ranges = []\n",
        "    for minute in highlight_minutes:\n",
        "        start_time = max(0, minute - padding_minutes) * 60  # Convert to seconds\n",
        "        end_time = (minute + padding_minutes) * 60\n",
        "        time_ranges.append((start_time, end_time))\n",
        "    \n",
        "    # Merge overlapping ranges\n",
        "    merged_ranges = []\n",
        "    if time_ranges:\n",
        "        time_ranges.sort()\n",
        "        current_start, current_end = time_ranges[0]\n",
        "        \n",
        "        for start, end in time_ranges[1:]:\n",
        "            if start <= current_end:  # Overlapping or adjacent\n",
        "                current_end = max(current_end, end)  # Extend current range\n",
        "            else:\n",
        "                merged_ranges.append((current_start, current_end))\n",
        "                current_start, current_end = start, end\n",
        "        \n",
        "        merged_ranges.append((current_start, current_end))\n",
        "    \n",
        "    # Generate EDL content\n",
        "    edl_lines = []\n",
        "    \n",
        "    # EDL header\n",
        "    edl_lines.append(\"TITLE: Highlights\")\n",
        "    edl_lines.append(\"FCM: NON-DROP FRAME\")\n",
        "    edl_lines.append(\"\")\n",
        "    \n",
        "    # Add each clip as an EDL event\n",
        "    current_timeline_time = 0  # Start at beginning of timeline\n",
        "    \n",
        "    for i, (start_sec, end_sec) in enumerate(merged_ranges, 1):\n",
        "        # Calculate duration\n",
        "        duration_sec = end_sec - start_sec\n",
        "        \n",
        "        # Convert to timecode (HH:MM:SS:FF)\n",
        "        source_start_tc = seconds_to_timecode(max(0, start_sec - offset_seconds), fps)\n",
        "        source_end_tc = seconds_to_timecode(max(0, end_sec - offset_seconds), fps)\n",
        "        timeline_start_tc = seconds_to_timecode(current_timeline_time, fps)\n",
        "        timeline_end_tc = seconds_to_timecode(current_timeline_time + duration_sec, fps)\n",
        "        \n",
        "        # EDL event number (padded to 3 digits)\n",
        "        event_num = f\"{i:03d}\"\n",
        "        \n",
        "        # Clip name\n",
        "        clip_name = f\"HIGHLIGHT_{i}\"\n",
        "        \n",
        "        # EDL event lines\n",
        "        edl_lines.append(f\"{event_num}  {clip_name}     V     C        {source_start_tc} {source_end_tc} {timeline_start_tc} {timeline_end_tc}\")\n",
        "        edl_lines.append(f\"* FROM CLIP NAME: {clip_name}\")\n",
        "        edl_lines.append(f\"* COMMENT: Highlight segment {i} - {seconds_to_readable(start_sec)} to {seconds_to_readable(end_sec)}\")\n",
        "        edl_lines.append(\"\")\n",
        "        \n",
        "        # Update timeline position\n",
        "        current_timeline_time += duration_sec\n",
        "    \n",
        "    # Write EDL file\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(edl_lines))\n",
        "    \n",
        "    print(f\"Generated EDL: {output_filename}\")\n",
        "    print(f\"Exported {len(merged_ranges)} highlight segments:\")\n",
        "    \n",
        "    for i, (start_sec, end_sec) in enumerate(merged_ranges, 1):\n",
        "        start_min = int(start_sec // 60)\n",
        "        start_sec_rem = int(start_sec % 60)\n",
        "        end_min = int(end_sec // 60)\n",
        "        end_sec_rem = int(end_sec % 60)\n",
        "        duration_min = int((end_sec - start_sec) // 60)\n",
        "        duration_sec = int((end_sec - start_sec) % 60)\n",
        "        \n",
        "        print(f\"  {i}. {start_min:02d}:{start_sec_rem:02d} - {end_min:02d}:{end_sec_rem:02d} (duration: {duration_min:02d}:{duration_sec:02d})\")\n",
        "\n",
        "def seconds_to_timecode(seconds, fps=30):\n",
        "    \"\"\"\n",
        "    Convert seconds to EDL timecode format (HH:MM:SS:FF).\n",
        "    \"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    frames = int((seconds % 1) * fps)\n",
        "    \n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}:{frames:02d}\"\n",
        "\n",
        "def seconds_to_readable(seconds):\n",
        "    \"\"\"\n",
        "    Convert seconds to readable time format.\n",
        "    \"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    \n",
        "    if hours > 0:\n",
        "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
        "    else:\n",
        "        return f\"{minutes:02d}:{secs:02d}\"\n",
        "\n",
        "# Generate EDL if highlights were detected\n",
        "if 'highlight_minutes' in locals() and highlight_minutes:\n",
        "    output_edl_file = f\"highlights_{YT_ID}.edl\"\n",
        "    \n",
        "    # Check if reshaping was applied and get offset\n",
        "    offset_seconds = 0\n",
        "    if 'start_time_seconds' in locals():\n",
        "        offset_seconds = start_time_seconds\n",
        "        print(f\"Applying offset of {offset_seconds} seconds ({offset_seconds//60:.0f}:{offset_seconds%60:02d}) from reshaping\")\n",
        "    \n",
        "    generate_edl(highlight_minutes, output_edl_file, padding_minutes=5, offset_seconds=offset_seconds)\n",
        "    \n",
        "    print(f\"\\nEDL file saved as: {output_edl_file}\")\n",
        "    print(\"Import this file into DaVinci Resolve using File > Import Timeline > EDL...\")\n",
        "    print(\"Or import into other NLEs like Premiere Pro, Final Cut Pro, etc.\")\n",
        "else:\n",
        "    print(\"No highlights detected. Run the highlight detection cell first.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "transcript-archiver",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
